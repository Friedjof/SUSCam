# SUSCam ğŸ‘ï¸ğŸ¥

**SUSCam** ist ein experimentelles Projekt zur Echtzeit-Personenerkennung und Kamerafernsteuerung mit Python, OpenCV und [MediaPipe](https://chuoling.github.io/mediapipe/) â€“ entwickelt fÃ¼r den Workshop â€SUSCamâ€œ beim [ASM25](https://www.muc.ccc.de/asm:25:start) des Chaos Computer Club MÃ¼nchen.

Ziel ist es, in kurzer Zeit einen funktionierenden Bildverarbeitungs-Workflow aufzubauen, mit dem Teilnehmer*innen visuelle Daten auswerten und gleichzeitig eine Kamera live per WebSocket steuern kÃ¶nnen. Die Anwendung ist bewusst offen gestaltet â€“ zum Hacken, Erweitern und Infragestellen.

> Sollte die externe Kamera nicht verfÃ¼gbar sein, wird automatisch auf eine lokale Webcam umgeschaltet. Die Schnittstellen bleiben dabei gleich â€“ allerdings sind dann motorisierte Funktionen deaktiviert.

## ğŸ¯ Mediapipe

[MediaPipe](https://chuoling.github.io/mediapipe/) ist eine Open-Source-Bibliothek von Google fÃ¼r Echtzeit-Computer-Vision-Anwendungen. Sie bringt leistungsfÃ¤hige Module wie Hand-, Gesichts- und KÃ¶rpererkennung direkt in Python-Projekte â€“ ohne tiefes Machine-Learning-Wissen.

Im Rahmen dieses Projekts dient MediaPipe zur schnellen Visualisierung und Analyse von Kameradaten â€“ ideal fÃ¼r interaktive Anwendungen wie â€Person verfolgenâ€œ, â€Hand zeigen = Kamera schwenktâ€œ oder eigene Ideen.

**Weitere Ressourcen:**

* [Setup-Anleitung fÃ¼r Python](https://ai.google.dev/edge/mediapipe/solutions/setup_python)
* [Gesture Recognition Guide](https://ai.google.dev/edge/mediapipe/solutions/vision/gesture_recognizer)
* [MediaPipe auf PyPI](https://pypi.org/project/mediapipe/)

---

## ğŸ•¹ï¸ Kamerafernsteuerung via WebSocket

Die Kamera im Projekt kann live Ã¼ber einfache WebSocket-Kommandos gesteuert werden â€“ etwa zur Positionierung, Frame-Abfrage oder Statusinfo.

| Befehl                | Funktion                            |
| --------------------- | ----------------------------------- |
| `getframe`            | Aktuelles Kamerabild senden         |
| `center`              | Kamera auf Startposition setzen     |
| `up/down`             | Kamera vertikal bewegen             |
| `left/right`          | Kamera horizontal bewegen           |
| `get_pos`             | Gibt aktuelle Position als JSON     |
| `get_limits`          | Gibt X/Y-Grenzen als JSON zurÃ¼ck    |
| `client_count`        | Gibt Anzahl verbundener Clients     |
| `{"x": 100, "y": 50}` | Direkte Positionssteuerung via JSON |
| `light_on/off`        | (Derzeit deaktiviert) Lichtsteuerung|

Das Steuerprotokoll ist einfach gehalten â€“ ideal fÃ¼r eigene Steuerungs-Apps, UIs oder Automatisierungen. Die Details findest du in [`tools/cam.py`](tools/cam.py).

---

## ğŸ“¦ Projektstruktur

```plaintext
SUSCam/
â”œâ”€â”€ .env                     # Umgebungsvariablen (z.B. Kamera-IP)
â”œâ”€â”€ app.py                   # Hauptstream-Anwendung mit OpenCV
â”œâ”€â”€ requirements.txt         # Python-AbhÃ¤ngigkeiten
â”œâ”€â”€ examples/                # Beispielskripte fÃ¼r Nutzung & Steuerung
â”‚   â”œâ”€â”€ camera_infos.py
â”‚   â”œâ”€â”€ camera_stream_mediapipe.py
â”‚   â”œâ”€â”€ camera_stream_opencv.py
â”‚   â””â”€â”€ move_camera.py
â””â”€â”€ tools/
    â””â”€â”€ cam.py               # Kamera-Klasse fÃ¼r Steuerung & Streaming
````

> FÃ¼r Umgebungsvariablen gibt es eine `.env`-Datei (siehe `.env.example` fÃ¼r Vorlage).

## â–¶ï¸ Schnellstart

1. Python-Umgebung vorbereiten:

```bash
git clone https://github.com/Friedjof/SUSCam.git
cd SUSCam
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt
```

2. `.env`-Datei anpassen:

```env
SUS_IP=192.168.XXX.XXX
```

3. Beispiele ausfÃ¼hren:

```bash
python examples/camera_stream_opencv.py
```

## ğŸ“ Beispiele (kurz erklÃ¤rt)

| Script                       | Zweck                                                   |
| ---------------------------- | ------------------------------------------------------- |
| `camera_infos.py`            | Liest Position, Limits und Clientanzahl Ã¼ber WebSocket. |
| `camera_stream_opencv.py`    | Zeigt den Live-Stream der Kamera mit OpenCV.            |
| `camera_stream_mediapipe.py` | Erweitert um Handerkennung via MediaPipe.               |
| `move_camera.py`             | FÃ¼hrt Bewegungsbefehle aus (links, rechts, usw.).       |

> Alle Skripte nutzen automatisch die in `.env` konfigurierte IP-Adresse.

## ğŸ“· Bonus: Virtuelle Kamera

Mit [pyvirtualcam](https://pypi.org/project/pyvirtualcam/) kann der Kamerastream als virtuelle Webcam bereitgestellt werden. So kÃ¶nnen andere Anwendungen (z.B. Videokonferenz-Tools) den Live-Stream nutzen.

### Ubuntu

```bash
sudo apt install v4l2loopback-dkms
sudo modprobe v4l2loopback devices=1 video_nr=10 card_label="SUSCam Virtual Camera" exclusive_caps=1
pip install pyvirtualcam
```

### Windows

```bash
pip install pyvirtualcam
```

## ğŸ” Hinweise

* Dieses Projekt ist ein Lern- und Diskussionswerkzeug â€“ kein fertiges Produkt.
* Datenschutz und ethische Aspekte sollten bei eigenen Anwendungen aktiv mitgedacht werden.
* Technische StÃ¶rungen (Netzwerk, Kamera, Betriebssystem-InkompatibilitÃ¤ten) kÃ¶nnen vorkommen â€“ es gibt Fallbacks.

## ğŸ“ Lizenz
Dieses Projekt steht unter der [MIT-Lizenz](LICENSE). Du kannst es frei nutzen, modifizieren und weiterverbreiten.

## ğŸ™‹ Mitmachen & Feedback

Dieses Projekt entstand im Rahmen des Workshops â€SUSCamâ€œ beim ASM25.
Fragen, Ideen oder Erweiterungen? â†’ Ã–ffne ein [Issue](https://github.com/Friedjof/SUSCam/issues) oder sprich mich beim ASM25 direkt an.